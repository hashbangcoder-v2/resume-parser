# Development Overrides
# This is the development configuration for the backend.

app:
  env: "dev"
  host: "0.0.0.0" # Listen on all interfaces for remote access
  port: 8000
  cors_origins:
    - "http://localhost:3000"
    - "http://127.0.0.1:3000"
    - "*" # Allow all for flexible dev

vllm:
  inference_args:
    gpu_memory_utilization: 0.5  # Use 30% of total GPU memory (~24GB) for 19GB free
    max_model_len: 8192
    enforce_eager: True
    tensor_parallel_size: 1
    trust_remote_code: True
  env_vars:
    PYTORCH_CUDA_ALLOC_CONF: 'expandable_segments:True,max_split_size_mb:512'
    CUDA_VISIBLE_DEVICES: 0
    CUDA_LAUNCH_BLOCKING: 0
    TORCH_CUDA_ALLOC_SYNC_MIN_VERSION: 1
    
    VLLM_USE_TRITON_FLASH_ATTN: 'true'  # Enable flash attention for A100
    VLLM_WORKER_MULTIPROC_METHOD: 'fork'  # Use fork instead of spawn on Linux
    VLLM_ATTENTION_BACKEND: 'FLASHINFER'
    VLLM_NO_USAGE_STATS: 1

  
logging:
  level: "DEBUG"
  file: "${oc.env:PROJECT_ROOT}/logs/backend_dev.log"

ai_model:
  default: "Qwen/Qwen2-7B-Instruct-AWQ"
  temperature: 0.2
  health_check_interval_seconds: 30
  health_check_timeout_seconds: 5  
  models:
    - "Qwen/Qwen2-7B-Instruct-AWQ"
    - "Qwen/Qwen2.5-Omni-7B"
    - "qwen3"

local_storage:
  path: "${oc.env:PROJECT_ROOT}/uploaded_resumes" 

database:
  create_if_not_exists: true  
  directory: "${oc.env:PROJECT_ROOT}/database"
  url: "sqlite:///${database.directory}/dev_candidates.db"